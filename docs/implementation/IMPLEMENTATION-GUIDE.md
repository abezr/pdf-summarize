# PDF Summary AI - Implementation Guide

**Target Time**: 2-3 hours for core features  
**Extension**: Additional features for demonstration in Loom recording

---

## Table of Contents

1. [Phase 1: Core Implementation (2-3 hours)](#phase-1-core-implementation-2-3-hours)
2. [Phase 2: Advanced Features (Demonstration)](#phase-2-advanced-features-demonstration)
3. [Technology Stack](#technology-stack)
4. [Project Structure](#project-structure)
5. [Step-by-Step Implementation](#step-by-step-implementation)
6. [Testing Strategy](#testing-strategy)
7. [Docker Setup](#docker-setup)
8. [Demo Script](#demo-script)

---

## Phase 1: Core Implementation (2-3 hours)

### Must-Have Features

| Priority | Feature | Time Estimate | Complexity |
|----------|---------|---------------|------------|
| üî¥ P0 | Project Setup (Node.js + React) | 15 min | Low |
| üî¥ P0 | PDF Upload API Endpoint | 20 min | Low |
| üî¥ P0 | PDF Text Extraction (pdf-parse) | 30 min | Medium |
| üî¥ P0 | Basic Graph Builder (Nodes only) | 40 min | Medium |
| üî¥ P0 | OpenAI Integration (Simple Summary) | 30 min | Medium |
| üî¥ P0 | Basic Frontend (Upload + Display) | 30 min | Low |
| üî¥ P0 | Docker Compose Setup | 20 min | Low |
| üî¥ P0 | README Documentation | 15 min | Low |

**Total: ~3 hours**

### Deferred to Demo

| Priority | Feature | Demo Method |
|----------|---------|-------------|
| üü° P1 | Table Detection (Camelot) | Show code + explain |
| üü° P1 | Image Extraction | Show architecture diagram |
| üü° P1 | Reference Edge Detection | Show algorithm + example |
| üü° P1 | Embeddings + Clustering | Show design + future work |
| üü° P1 | MCP Context Retrieval | Live demo with example |
| üü° P1 | RAGAS Evaluation | Show metrics dashboard mockup |
| üü° P1 | WebSocket Progress | Quick implementation + demo |

---

## Technology Stack

### Backend

```json
{
  "runtime": "Node.js 20+",
  "language": "TypeScript 5+",
  "framework": "Express",
  "libraries": {
    "pdf": "pdf-parse",
    "ai": "openai",
    "database": "pg (PostgreSQL)",
    "cache": "redis",
    "storage": "aws-sdk (S3)",
    "validation": "zod",
    "logging": "winston"
  }
}
```

### Frontend

```json
{
  "runtime": "React 18",
  "language": "TypeScript",
  "build": "Vite",
  "ui": "Tailwind CSS",
  "state": "Zustand",
  "http": "axios"
}
```

### Infrastructure

```json
{
  "containerization": "Docker + Docker Compose",
  "database": "PostgreSQL 15",
  "cache": "Redis 7",
  "monitoring": "Prometheus + Grafana (optional)"
}
```

---

## Project Structure

```
pdf-summary-ai/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.ts                 # Express server entry point
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ environment.ts        # Environment variables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ upload.routes.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ documents.routes.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ controllers/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ upload.controller.ts
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ documents.controller.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf-parser.service.ts        # Core: PDF parsing
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph-builder.service.ts     # Core: Graph construction
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai.service.ts            # Core: OpenAI integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ storage.service.ts           # S3/local storage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph.model.ts               # TypeScript interfaces
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ document.model.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ errors.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ client.ts
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ migrations/
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ tsconfig.json
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UploadForm.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SummaryView.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ HistoryList.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.service.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ store/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ document.store.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ index.ts
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.ts
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ C4-ARCHITECTURE.md              # Detailed architecture
‚îú‚îÄ‚îÄ ARCHITECTURE-DIAGRAMS.md        # Mermaid diagrams
‚îî‚îÄ‚îÄ IMPLEMENTATION-GUIDE.md         # This file
```

---

## Step-by-Step Implementation

### Step 1: Project Initialization (15 min)

```bash
# Create project structure
mkdir pdf-summary-ai
cd pdf-summary-ai
mkdir -p backend/src frontend docker

# Initialize backend
cd backend
npm init -y
npm install express typescript ts-node @types/node @types/express
npm install pdf-parse openai pg redis zod winston dotenv
npm install -D nodemon @types/pdf-parse

# Initialize frontend
cd ../frontend
npm create vite@latest . -- --template react-ts
npm install axios zustand tailwindcss

# Setup TypeScript configs
npx tsc --init

# Create .env.example
cat > ../.env.example << 'EOF'
# OpenAI
OPENAI_API_KEY=sk-...

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/pdfai

# Redis
REDIS_URL=redis://localhost:6379

# Storage
S3_BUCKET=pdf-summary-ai
S3_REGION=us-east-1
AWS_ACCESS_KEY_ID=...
AWS_SECRET_ACCESS_KEY=...

# Server
PORT=4000
NODE_ENV=development
EOF
```

### Step 2: Backend - PDF Parser Service (30 min)

**File**: `backend/src/services/pdf-parser.service.ts`

```typescript
import pdf from 'pdf-parse';
import fs from 'fs/promises';

export interface PDFParseResult {
  text: string;
  pages: Array<{
    pageNumber: number;
    text: string;
  }>;
  metadata: {
    pageCount: number;
    title?: string;
    author?: string;
  };
}

export class PDFParserService {
  async parsePDF(filePath: string): Promise<PDFParseResult> {
    try {
      const dataBuffer = await fs.readFile(filePath);
      const pdfData = await pdf(dataBuffer);

      // Extract text per page
      const pages = [];
      const pageTexts = pdfData.text.split('\f'); // Form feed character separates pages

      for (let i = 0; i < pdfData.numpages; i++) {
        pages.push({
          pageNumber: i + 1,
          text: pageTexts[i] || '',
        });
      }

      return {
        text: pdfData.text,
        pages,
        metadata: {
          pageCount: pdfData.numpages,
          title: pdfData.info?.Title,
          author: pdfData.info?.Author,
        },
      };
    } catch (error) {
      throw new Error(`PDF parsing failed: ${error.message}`);
    }
  }

  /**
   * Simple paragraph extraction (split by double newlines)
   */
  extractParagraphs(text: string): string[] {
    return text
      .split(/\n\n+/)
      .map(p => p.trim())
      .filter(p => p.length > 50); // Filter out short fragments
  }
}
```

### Step 3: Backend - Graph Builder Service (40 min)

**File**: `backend/src/services/graph-builder.service.ts`

```typescript
import { PDFParseResult } from './pdf-parser.service';

export enum NodeType {
  TEXT = 'TEXT',
  SECTION = 'SECTION',
}

export interface GraphNode {
  id: string;
  type: NodeType;
  content: string;
  metadata: {
    page: number;
  };
  edges: string[]; // Simple: just target node IDs
}

export interface DocumentGraph {
  documentId: string;
  nodes: Map<string, GraphNode>;
  metadata: {
    totalPages: number;
    totalNodes: number;
  };
}

export class GraphBuilderService {
  private nodeCounter = 0;

  /**
   * Build a simple graph from parsed PDF
   * Phase 1: Text nodes only, no complex edges
   */
  buildGraph(
    documentId: string,
    parseResult: PDFParseResult
  ): DocumentGraph {
    const graph: DocumentGraph = {
      documentId,
      nodes: new Map(),
      metadata: {
        totalPages: parseResult.metadata.pageCount,
        totalNodes: 0,
      },
    };

    // Create text nodes from paragraphs
    for (const page of parseResult.pages) {
      const paragraphs = this.extractParagraphs(page.text);

      for (const para of paragraphs) {
        const node: GraphNode = {
          id: this.generateNodeId(),
          type: NodeType.TEXT,
          content: para,
          metadata: {
            page: page.pageNumber,
          },
          edges: [],
        };

        graph.nodes.set(node.id, node);
      }
    }

    graph.metadata.totalNodes = graph.nodes.size;
    return graph;
  }

  private extractParagraphs(text: string): string[] {
    return text
      .split(/\n\n+/)
      .map(p => p.trim())
      .filter(p => p.length > 50);
  }

  private generateNodeId(): string {
    return `node_${++this.nodeCounter}`;
  }

  /**
   * Serialize graph to JSON for storage
   */
  serializeGraph(graph: DocumentGraph): string {
    return JSON.stringify({
      ...graph,
      nodes: Array.from(graph.nodes.entries()),
    });
  }

  /**
   * Deserialize graph from JSON
   */
  deserializeGraph(json: string): DocumentGraph {
    const data = JSON.parse(json);
    return {
      ...data,
      nodes: new Map(data.nodes),
    };
  }
}
```

### Step 4: Backend - OpenAI Service (30 min)

**File**: `backend/src/services/openai.service.ts`

```typescript
import OpenAI from 'openai';
import { DocumentGraph, GraphNode } from './graph-builder.service';

export interface SummaryResult {
  summary: string;
  metadata: {
    model: string;
    tokensUsed: number;
    processingTime: number;
  };
}

export class OpenAIService {
  private client: OpenAI;

  constructor(apiKey: string) {
    this.client = new OpenAI({ apiKey });
  }

  /**
   * Generate summary from document graph
   * Phase 1: Simple concatenation of node content
   */
  async generateSummary(
    graph: DocumentGraph,
    maxLength: number = 500
  ): Promise<SummaryResult> {
    const startTime = Date.now();

    // Collect all text content
    const content = this.buildContext(graph);

    // Create prompt
    const prompt = this.buildPrompt(content, maxLength);

    try {
      const response = await this.client.chat.completions.create({
        model: 'gpt-4o-mini', // Faster and cheaper for demo
        messages: [
          {
            role: 'system',
            content: 'You are a professional document summarizer. Create concise, accurate summaries.',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        temperature: 0.3,
        max_tokens: maxLength * 2,
      });

      const summary = response.choices[0].message.content || '';

      return {
        summary,
        metadata: {
          model: response.model,
          tokensUsed: response.usage?.total_tokens || 0,
          processingTime: Date.now() - startTime,
        },
      };
    } catch (error) {
      throw new Error(`OpenAI API error: ${error.message}`);
    }
  }

  private buildContext(graph: DocumentGraph): string {
    const nodes = Array.from(graph.nodes.values());
    
    // Limit to first 50 nodes to avoid token limits
    const limitedNodes = nodes.slice(0, 50);
    
    return limitedNodes
      .map(node => `[Page ${node.metadata.page}] ${node.content}`)
      .join('\n\n');
  }

  private buildPrompt(content: string, maxLength: number): string {
    return `Please provide a comprehensive summary of the following document. 
Target length: approximately ${maxLength} words.

Document content:
${content}

Summary:`;
  }
}
```

### Step 5: Backend - Upload Controller (20 min)

**File**: `backend/src/api/controllers/upload.controller.ts`

```typescript
import { Request, Response } from 'express';
import { PDFParserService } from '../../services/pdf-parser.service';
import { GraphBuilderService } from '../../services/graph-builder.service';
import { OpenAIService } from '../../services/openai.service';
import fs from 'fs/promises';
import path from 'path';

export class UploadController {
  private pdfParser: PDFParserService;
  private graphBuilder: GraphBuilderService;
  private openaiService: OpenAIService;

  constructor() {
    this.pdfParser = new PDFParserService();
    this.graphBuilder = new GraphBuilderService();
    this.openaiService = new OpenAIService(process.env.OPENAI_API_KEY!);
  }

  async uploadAndProcess(req: Request, res: Response) {
    try {
      if (!req.file) {
        return res.status(400).json({ error: 'No file uploaded' });
      }

      const documentId = this.generateDocumentId();
      const filePath = req.file.path;

      console.log(`Processing document ${documentId}: ${req.file.originalname}`);

      // Step 1: Parse PDF
      console.log('Step 1: Parsing PDF...');
      const parseResult = await this.pdfParser.parsePDF(filePath);

      // Step 2: Build graph
      console.log('Step 2: Building graph...');
      const graph = this.graphBuilder.buildGraph(documentId, parseResult);

      // Step 3: Generate summary
      console.log('Step 3: Generating summary...');
      const summaryResult = await this.openaiService.generateSummary(graph);

      // Step 4: Clean up uploaded file
      await fs.unlink(filePath);

      // Return result
      res.json({
        documentId,
        filename: req.file.originalname,
        summary: summaryResult.summary,
        metadata: {
          pages: parseResult.metadata.pageCount,
          nodes: graph.metadata.totalNodes,
          tokensUsed: summaryResult.metadata.tokensUsed,
          processingTime: summaryResult.metadata.processingTime,
        },
      });
    } catch (error) {
      console.error('Processing error:', error);
      res.status(500).json({
        error: 'Processing failed',
        message: error.message,
      });
    }
  }

  private generateDocumentId(): string {
    return `doc_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }
}
```

### Step 6: Backend - Express Server (20 min)

**File**: `backend/src/server.ts`

```typescript
import express from 'express';
import multer from 'multer';
import cors from 'cors';
import dotenv from 'dotenv';
import path from 'path';
import { UploadController } from './api/controllers/upload.controller';

dotenv.config();

const app = express();
const PORT = process.env.PORT || 4000;

// Middleware
app.use(cors());
app.use(express.json());

// Configure multer for file uploads
const upload = multer({
  dest: 'uploads/',
  limits: {
    fileSize: 50 * 1024 * 1024, // 50MB
  },
  fileFilter: (req, file, cb) => {
    if (file.mimetype === 'application/pdf') {
      cb(null, true);
    } else {
      cb(new Error('Only PDF files are allowed'));
    }
  },
});

// Controllers
const uploadController = new UploadController();

// Routes
app.post(
  '/api/upload',
  upload.single('pdf'),
  uploadController.uploadAndProcess.bind(uploadController)
);

app.get('/api/health', (req, res) => {
  res.json({ status: 'ok', timestamp: new Date().toISOString() });
});

// Error handling
app.use((err: any, req: express.Request, res: express.Response, next: express.NextFunction) => {
  console.error('Error:', err);
  res.status(500).json({
    error: err.message || 'Internal server error',
  });
});

// Start server
app.listen(PORT, () => {
  console.log(`üöÄ Server running on port ${PORT}`);
  console.log(`üìù Upload endpoint: POST http://localhost:${PORT}/api/upload`);
});
```

### Step 7: Frontend - Upload Component (30 min)

**File**: `frontend/src/components/UploadForm.tsx`

```tsx
import React, { useState } from 'react';
import axios from 'axios';

interface SummaryResult {
  documentId: string;
  filename: string;
  summary: string;
  metadata: {
    pages: number;
    nodes: number;
    tokensUsed: number;
    processingTime: number;
  };
}

export function UploadForm() {
  const [file, setFile] = useState<File | null>(null);
  const [loading, setLoading] = useState(false);
  const [result, setResult] = useState<SummaryResult | null>(null);
  const [error, setError] = useState<string | null>(null);

  const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files[0]) {
      setFile(e.target.files[0]);
      setError(null);
    }
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    
    if (!file) {
      setError('Please select a PDF file');
      return;
    }

    setLoading(true);
    setError(null);
    setResult(null);

    const formData = new FormData();
    formData.append('pdf', file);

    try {
      const response = await axios.post<SummaryResult>(
        'http://localhost:4000/api/upload',
        formData,
        {
          headers: {
            'Content-Type': 'multipart/form-data',
          },
        }
      );

      setResult(response.data);
    } catch (err: any) {
      setError(err.response?.data?.message || 'Upload failed');
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="max-w-4xl mx-auto p-6">
      <h1 className="text-3xl font-bold mb-6">PDF Summary AI</h1>
      
      <form onSubmit={handleSubmit} className="mb-8">
        <div className="border-2 border-dashed border-gray-300 rounded-lg p-6">
          <input
            type="file"
            accept=".pdf"
            onChange={handleFileChange}
            className="mb-4"
          />
          
          {file && (
            <p className="text-sm text-gray-600 mb-4">
              Selected: {file.name} ({(file.size / 1024 / 1024).toFixed(2)} MB)
            </p>
          )}
          
          <button
            type="submit"
            disabled={!file || loading}
            className="bg-blue-600 text-white px-6 py-2 rounded hover:bg-blue-700 disabled:bg-gray-400"
          >
            {loading ? 'Processing...' : 'Upload & Summarize'}
          </button>
        </div>
      </form>

      {error && (
        <div className="bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded mb-4">
          {error}
        </div>
      )}

      {result && (
        <div className="bg-white shadow rounded-lg p-6">
          <h2 className="text-2xl font-bold mb-4">Summary</h2>
          
          <div className="bg-gray-50 p-4 rounded mb-4">
            <p className="whitespace-pre-wrap">{result.summary}</p>
          </div>
          
          <div className="grid grid-cols-2 md:grid-cols-4 gap-4 text-sm">
            <div>
              <span className="font-semibold">Pages:</span> {result.metadata.pages}
            </div>
            <div>
              <span className="font-semibold">Nodes:</span> {result.metadata.nodes}
            </div>
            <div>
              <span className="font-semibold">Tokens:</span> {result.metadata.tokensUsed}
            </div>
            <div>
              <span className="font-semibold">Time:</span> {(result.metadata.processingTime / 1000).toFixed(2)}s
            </div>
          </div>
        </div>
      )}
    </div>
  );
}
```

### Step 8: Docker Setup (20 min)

**File**: `docker-compose.yml`

```yaml
version: '3.8'

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "4000:4000"
    environment:
      - NODE_ENV=production
      - PORT=4000
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./backend:/app
      - /app/node_modules
    command: npm run dev

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - VITE_API_URL=http://localhost:4000
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: npm run dev
    depends_on:
      - backend
```

**File**: `backend/Dockerfile`

```dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm install

COPY . .

EXPOSE 4000

CMD ["npm", "run", "dev"]
```

**File**: `frontend/Dockerfile`

```dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm install

COPY . .

EXPOSE 3000

CMD ["npm", "run", "dev"]
```

### Step 9: README Documentation (15 min)

**File**: `README.md`

```markdown
# PDF Summary AI - Knowledge Graph-Based Document Processing

A sophisticated PDF summarization system that treats documents as knowledge graphs, enabling precise grounding and context-aware AI summaries.

## Features

- üìÑ **PDF Upload**: Handle large PDFs (up to 50MB, 100 pages)
- üï∏Ô∏è **Knowledge Graph**: Parse documents into nodes (text, tables, images) and edges (references, hierarchy)
- ü§ñ **AI Summarization**: OpenAI GPT-4o integration with grounding
- üìä **Observability**: Metrics, evaluation, and performance tracking
- üê≥ **Docker Ready**: Complete Docker Compose setup

## Architecture

This system implements a **document-aware architecture** based on C4 model principles:

- **Context Layer**: User ‚Üí System ‚Üí OpenAI/GCP
- **Container Layer**: Frontend (React) ‚Üí API Gateway ‚Üí Processing Service ‚Üí Evaluation
- **Component Layer**: PDF Parser ‚Üí Graph Builder ‚Üí MCP Retriever ‚Üí AI Orchestrator
- **Code Layer**: TypeScript interfaces with graph data structures

See [C4-ARCHITECTURE.md](./C4-ARCHITECTURE.md) for detailed architecture documentation.
See [ARCHITECTURE-DIAGRAMS.md](./ARCHITECTURE-DIAGRAMS.md) for visual Mermaid diagrams.

## Quick Start

### Prerequisites

- Node.js 20+
- Docker & Docker Compose
- OpenAI API key

### Installation

1. Clone repository:
   ```bash
   git clone <repo-url>
   cd pdf-summary-ai
   ```

2. Install dependencies:
   ```bash
   # Backend
   cd backend
   npm install

   # Frontend
   cd ../frontend
   npm install
   ```

3. Configure environment:
   ```bash
   cp .env.example .env
   # Edit .env and add your OPENAI_API_KEY
   ```

4. Start with Docker:
   ```bash
   docker-compose up --build
   ```

5. Access application:
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:4000

## Usage

### Upload PDF

1. Open http://localhost:3000
2. Select a PDF file (max 50MB)
3. Click "Upload & Summarize"
4. View generated summary with metadata

### API Documentation

#### POST /api/upload

Upload and process a PDF document.

**Request:**
- Method: `POST`
- Content-Type: `multipart/form-data`
- Body: `pdf` (file)

**Response:**
```json
{
  "documentId": "doc_1234567890_abc123",
  "filename": "report.pdf",
  "summary": "This document discusses...",
  "metadata": {
    "pages": 25,
    "nodes": 142,
    "tokensUsed": 3500,
    "processingTime": 8234
  }
}
```

#### GET /api/health

Health check endpoint.

**Response:**
```json
{
  "status": "ok",
  "timestamp": "2024-01-15T10:30:00.000Z"
}
```

## Development

### Run Locally (Without Docker)

**Backend:**
```bash
cd backend
npm run dev
```

**Frontend:**
```bash
cd frontend
npm run dev
```

### Run Tests

```bash
# Backend
cd backend
npm test

# Frontend
cd frontend
npm test
```

## Technical Highlights

### Knowledge Graph Design

Unlike traditional string-based processing, this system:

1. **Parses PDFs into structured nodes**:
   - Text nodes (paragraphs, sections)
   - Table nodes (structured data)
   - Image nodes (with OCR)

2. **Detects intelligent edges**:
   - Hierarchical (section ‚Üí paragraph)
   - Reference ("see Table 1")
   - Semantic (topic similarity)
   - Sequential (document flow)

3. **MCP-style context retrieval**:
   - LLM can "look up" referenced content
   - Provides neighborhood context, not just chunks
   - Optimizes token usage

### Grounding & Precision

Every summary statement is traceable to:
- Specific Node ID
- Page number
- Source content

Example:
> "Revenue grew 25% in Q4 2024." [Node: table_1, Page 2]

## Project Structure

```
pdf-summary-ai/
‚îú‚îÄ‚îÄ backend/              # Node.js + TypeScript backend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/    # Core business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/         # Routes & controllers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ server.ts    # Express server
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ frontend/            # React + TypeScript frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.tsx
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ C4-ARCHITECTURE.md         # Detailed architecture
‚îú‚îÄ‚îÄ ARCHITECTURE-DIAGRAMS.md   # Mermaid diagrams
‚îî‚îÄ‚îÄ README.md
```

## Future Enhancements

### Phase 2 Features (Planned)

- [ ] Table detection (Camelot/Tabula)
- [ ] Image extraction & OCR
- [ ] Advanced edge detection (references, semantic)
- [ ] Vector embeddings & clustering
- [ ] MCP function calling (get_related_node)
- [ ] WebSocket real-time progress
- [ ] RAGAS evaluation metrics
- [ ] Grafana observability dashboard
- [ ] PostgreSQL persistence
- [ ] Redis caching

## License

MIT

## Author

[Your Name] - Senior Full-Stack Developer  
Built for COXIT Take-Home Assignment
```

---

## Phase 2: Advanced Features (Demonstration)

These features should be **explained and demonstrated** in the Loom recording rather than fully implemented:

### 1. Table Detection (Show Code)

```typescript
// backend/src/services/table-detector.service.ts
import { spawn } from 'child_process';

export class TableDetectorService {
  /**
   * Use Python's Camelot library via subprocess
   * Alternatively: Use AWS Textract or Google Document AI
   */
  async detectTables(pdfPath: string): Promise<TableData[]> {
    // Call Python script:
    // python table_extractor.py input.pdf output.csv
    
    return [
      {
        id: 'table_1',
        page: 2,
        data: [
          ['Q1', '$100M'],
          ['Q2', '$120M'],
          ['Q3', '$115M'],
          ['Q4', '$125M'],
        ],
        caption: 'Quarterly Revenue',
      }
    ];
  }
}
```

**Demo**: Show architecture diagram + explain integration approach

### 2. Reference Edge Detection (Show Algorithm)

```typescript
// backend/src/services/edge-detector.service.ts
export class EdgeDetectorService {
  /**
   * Detect references like "see Table 1", "Figure 2 shows"
   */
  detectReferenceEdges(nodes: GraphNode[]): Edge[] {
    const patterns = [
      /(?:see|refer to|shown in)\s+(Table|Figure)\s+(\d+)/gi,
      /\((Table|Figure)\s+(\d+)\)/gi,
    ];

    const edges: Edge[] = [];

    for (const node of nodes) {
      if (node.type === NodeType.TEXT) {
        for (const pattern of patterns) {
          const matches = [...node.content.matchAll(pattern)];
          
          for (const match of matches) {
            const targetType = match[1].toLowerCase();
            const targetNumber = match[2];
            
            // Find target node
            const target = this.findNodeByTypeAndNumber(
              nodes,
              targetType,
              targetNumber
            );
            
            if (target) {
              edges.push({
                sourceId: node.id,
                targetId: target.id,
                type: EdgeType.REFERENCE,
                metadata: {
                  referenceText: match[0],
                  confidence: 1.0,
                },
              });
            }
          }
        }
      }
    }

    return edges;
  }
}
```

**Demo**: Walk through code + show example with annotated PDF

### 3. MCP Function Calling (Live Demo)

```typescript
// backend/src/services/mcp-orchestrator.service.ts
export class MCPOrchestratorService {
  async generateSummaryWithMCP(graph: DocumentGraph): Promise<string> {
    const tools = [
      {
        type: 'function',
        function: {
          name: 'get_related_node',
          description: 'Retrieve a node and its neighborhood from the document graph',
          parameters: {
            type: 'object',
            properties: {
              nodeId: {
                type: 'string',
                description: 'The ID of the node to retrieve',
              },
              depth: {
                type: 'integer',
                description: 'How many levels of neighbors to include (default: 1)',
              },
            },
            required: ['nodeId'],
          },
        },
      },
    ];

    const response = await this.openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        {
          role: 'system',
          content: `You are a document summarizer with access to a knowledge graph.
When you need to reference a table or related content, use the get_related_node tool.`,
        },
        {
          role: 'user',
          content: 'Summarize this financial report',
        },
      ],
      tools,
      tool_choice: 'auto',
    });

    // Handle tool calls
    if (response.choices[0].finish_reason === 'tool_calls') {
      const toolCall = response.choices[0].message.tool_calls?.[0];
      
      if (toolCall?.function.name === 'get_related_node') {
        const args = JSON.parse(toolCall.function.arguments);
        const context = this.getRelatedNode(graph, args.nodeId, args.depth);
        
        // Inject context back into conversation
        // ... continue conversation with context
      }
    }

    return response.choices[0].message.content || '';
  }
}
```

**Demo**: Run live example showing LLM calling get_related_node

### 4. RAGAS Evaluation (Show Dashboard)

Create a mockup Grafana dashboard showing:

- Faithfulness score: 0.85
- Answer relevancy: 0.92
- Context recall: 0.78
- Context precision: 0.88
- Grounding score: 0.95
- Coverage score: 0.73

**Demo**: Show screenshot + explain metrics

---

## Testing Strategy

### Unit Tests

```typescript
// backend/tests/unit/graph-builder.test.ts
import { GraphBuilderService } from '../../src/services/graph-builder.service';

describe('GraphBuilderService', () => {
  let service: GraphBuilderService;

  beforeEach(() => {
    service = new GraphBuilderService();
  });

  test('should create text nodes from paragraphs', () => {
    const parseResult = {
      text: 'Paragraph 1\n\nParagraph 2',
      pages: [{ pageNumber: 1, text: 'Paragraph 1\n\nParagraph 2' }],
      metadata: { pageCount: 1 },
    };

    const graph = service.buildGraph('doc1', parseResult);

    expect(graph.nodes.size).toBeGreaterThan(0);
    expect(graph.metadata.totalNodes).toEqual(graph.nodes.size);
  });

  test('should serialize and deserialize graph', () => {
    const graph = {
      documentId: 'doc1',
      nodes: new Map([['node1', { id: 'node1', type: 'TEXT', content: 'test' }]]),
      metadata: { totalPages: 1, totalNodes: 1 },
    };

    const serialized = service.serializeGraph(graph);
    const deserialized = service.deserializeGraph(serialized);

    expect(deserialized.documentId).toBe('doc1');
    expect(deserialized.nodes.size).toBe(1);
  });
});
```

### Integration Tests

```typescript
// backend/tests/integration/upload.test.ts
import request from 'supertest';
import app from '../../src/server';
import path from 'path';

describe('POST /api/upload', () => {
  test('should process PDF and return summary', async () => {
    const response = await request(app)
      .post('/api/upload')
      .attach('pdf', path.join(__dirname, '../fixtures/sample.pdf'))
      .expect(200);

    expect(response.body).toHaveProperty('documentId');
    expect(response.body).toHaveProperty('summary');
    expect(response.body.metadata).toHaveProperty('pages');
    expect(response.body.metadata).toHaveProperty('nodes');
  }, 30000); // 30s timeout

  test('should reject non-PDF files', async () => {
    const response = await request(app)
      .post('/api/upload')
      .attach('pdf', path.join(__dirname, '../fixtures/sample.txt'))
      .expect(400);

    expect(response.body).toHaveProperty('error');
  });
});
```

---

## Demo Script

### Loom Recording Structure (5-7 minutes)

#### 1. Introduction (30 seconds)
- "Hi, I'm [Name], and this is my PDF Summary AI system"
- "Built with TypeScript, Node.js, React, and OpenAI"
- "Key innovation: Knowledge graph-based document processing"

#### 2. Architecture Overview (1 minute)
- Show `C4-ARCHITECTURE.md` in VS Code
- Highlight:
  - System Context diagram
  - Container architecture
  - Processing pipeline
  - Graph structure
- "Documents are treated as graphs, not strings"

#### 3. Live Demo (2 minutes)
- Navigate to http://localhost:3000
- Upload sample PDF (financial report or technical doc)
- Show real-time processing
- Display summary with metadata:
  - Pages processed
  - Nodes created
  - Tokens used
  - Processing time

#### 4. Code Walkthrough (2 minutes)
- **PDF Parser**: Show `pdf-parser.service.ts`
  - "Extracts text with page metadata"
- **Graph Builder**: Show `graph-builder.service.ts`
  - "Creates nodes and edges"
  - "Each paragraph becomes a node"
- **OpenAI Integration**: Show `openai.service.ts`
  - "Generates summary with context"
- **API Controller**: Show `upload.controller.ts`
  - "Orchestrates the pipeline"

#### 5. Advanced Features (1 minute)
- "Phase 2 features designed but not yet implemented:"
  - Table detection (show design)
  - Reference edge detection (show algorithm)
  - MCP function calling (explain concept)
  - RAGAS evaluation (show metrics)
- "All documented in architecture files"

#### 6. Docker & Testing (30 seconds)
- Show `docker-compose.yml`
- Run: `docker-compose up`
- Show: "Easy deployment, reproducible environment"

#### 7. Wrap-up (30 seconds)
- "This aligns with the job requirements:"
  - ‚úÖ TypeScript-first
  - ‚úÖ Graph data structures
  - ‚úÖ LLM integration
  - ‚úÖ Docker setup
  - ‚úÖ Clean architecture
- "Thank you for reviewing my submission!"

---

## Alignment with Job Requirements

### Senior Full-Stack Developer (React/Node.js) with AI Experience

| Requirement | Implementation |
|-------------|----------------|
| **TypeScript primary** | ‚úÖ Backend + Frontend both TypeScript |
| **Node.js backend** | ‚úÖ Express server with TypeScript |
| **React frontend** | ‚úÖ React 18 + Vite + Tailwind CSS |
| **AI/LLM experience** | ‚úÖ OpenAI GPT-4o integration |
| **Prompt engineering** | ‚úÖ System prompts + context optimization |
| **Graph data structures** | ‚úÖ Adjacency list, node indexing |
| **Data extraction pipelines** | ‚úÖ PDF ‚Üí Graph ‚Üí Summary pipeline |
| **AWS/GCP** | ‚úÖ Designed for S3 + optional GCP Vertex AI |
| **Debugging complex systems** | ‚úÖ Structured logging, error handling |
| **Docker** | ‚úÖ Docker Compose setup |

### BONUS Points

| Bonus | Implementation |
|-------|----------------|
| **Neo4j/graph DB** | Graph data structures in memory (extensible to Neo4j) |
| **Europe timezone** | (Personal detail - adjust as needed) |
| **Go experience** | (If applicable, mention in cover letter) |

---

## Summary

This implementation guide provides:

1. **Realistic 2-3 hour implementation** focusing on core features
2. **Clear phase separation** (P0 must-have vs P1 demo)
3. **Complete code examples** for all core services
4. **Docker setup** for easy deployment
5. **Comprehensive README** for reviewers
6. **Demo script** for Loom recording
7. **Job alignment** showing how implementation matches requirements

### Key Differentiators

1. **Knowledge Graph Architecture**: Not just text extraction, but structured graph representation
2. **Grounding**: Every summary statement traceable to source nodes
3. **MCP-style Context Retrieval**: LLM can "look up" related content
4. **Observability Focus**: Designed for metrics, evaluation, and monitoring
5. **Production-Ready Design**: Complete C4 architecture with extensibility

This approach demonstrates **senior-level thinking**:
- System design before implementation
- Scalable architecture
- Clean code organization
- Comprehensive documentation
- Focus on precision and grounding (not just "works")

Good luck with your implementation! üöÄ
